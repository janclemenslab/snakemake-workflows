# Snakemake workflows
For use as [wrappers](https://snakemake.readthedocs.io/en/stable/snakefiles/modularization.html#wrappers) in snakefiles

## File organization
Each type of rig is housed in `#Common/RIGNAME` with the following subfolders and files:

- `dat` - data to be analyzed (regularly move these into `dat.processed`)
- `dat.processed` - data with completed analyses
- `res` - analysis results
- `log` - analysis logs
- `workflow` - see _Rules_ below
- `fabfile.py` (need to update `NAME` variable to the RIGNAME) with at least `pull`, `push`, `submit`.

## How the system works
- list files
- get analysis profile for each file (either file specific from `dat/EXPTNAME/EXPTNAME_analysis.yaml` or from defaults in `workflow/analysis_profiles/default.yaml`)
- scan the analysis profile for which rules to run for that file - keys in the profile need to match rule name - and for the name of the output files - general form is `dat/EXPTNAME/EXPTNAME_SUFFIX.EXTENSION`, with `SUFFIX` defaulting to the rule name and `EXTENSION` defaulting to `h5`
- then run all rules in the list - snakemake takes care of dependencies
- job parameters are taken from the analysis profile


## Rules

### Defining new snakemake rules


```yaml
# list all rules that should be executed on the cluster:
rule all:
    targets[RULENAME], targets[OTHER_RULENAME]

# useful if you want to only run one rule:
rule RULENAME_all:
    targets[RULENAME]

# specify the rule here:
rule RULENAME:
    input:
        video="dat/{directory}/{directory}.mp4",
    params:
        read_annotations,  # load rule-specific parameters from `dat/{directory}/{directory}_analysis.yaml`
        # request resources on the cluster
        ntasks="2",
        # add suffix RULENAME to slurm log file (optional)
        output="{directory}_RULENAME.log",
    envmodules:
        "cuda10.1/toolkit/10.1.105",
    output: "res/{directory}/{directory}_RULENAME.h5",  # add suffix RULENAME to output file (required!)
    wrapper: "file:workflow/WRAPPER"
```
- `input`: Experiment-specific files required by the wrapper.
- `output`: The name of the file created by the rule. Defaults to `res/{directory}/{directory}_RULENAME.h5`, you can override the suffix `RULENAME` and `h5` in the filename with the `suffix` and extension fields in the analysis file. __Important__: This needs to match the settings in the `dat/EXPTNAME/EXPTNAME_analysis.yaml` or the default `workflow/analysis_profiles/default.yaml` - otherwise, snakemake will not be able to associate
- `params`: There are two different types of parameters:
    - _generic_ for requesting resources on the cluster
	- _expt-specific_ these are not specified in the snakefile but in `dat/EXPTNAME/EXPTNAME_analysis.yaml`, each with one block of parameters per `RULENAME`. Read by `utils.read_annotations` in the rule. Parameters will be used e.g. to form command line or function args  - this file will be generated by annotator GUI:
```yaml
RULENAME:
    PARAM: VALUE
    param2: 'minor'
    extension: zarr  # optional, defaults to h5 if missing. only use when your wrapper creates a file not ending in `.h5`
    suffix: dodo  # optional, defaults to RULENAME if missing
RULENAME_OTHER:
    param1: 0.75
    param2: [920, 1020]
```
Default naming convention for outputs, `res/EXPTNAME/EXPTNAME_RULENAME.h5`. This can be overriden with `suffix` and `extension`to `res/EXPTNAME/EXPTNAME_{suffix}.{extension}`.

Will use `workflow/analysis_profiles/default.yaml` if that file does not exist. Note that the default schema needs to have an entry for each rule - otherwise the rule will not be run. Right now you have to create a "dummy" entry that starts with the rulename followed by a `.`. The following will run the `spd` rule is run. This is not great since this will create a check box in the annotator GUI, giving the illusion that this is - but the param value will be ignored and the `spd` irrespective of the state of this field.
```yaml
- name: spd.
  label: postprocess tracks (dummy option - will be run regardless of selection)
  type: bool
  default: True
```


- `envmodules`: For loading binary libraries required by the wrapper on the cluster. Each value should replace `ENVMODULE` in `module load ENVMODULE`. We currently only use that to load CUDA related libraries for running tensorflow on the cluster. Make sure the CUDA versions match those required by the specific version of tensorflow used in the wrapper environment (see [tensorflow docs](https://www.tensorflow.org/install/source#tested_build_configurations)).
- `wrapper`: Defines code for creating the output from the inputs. Each wrapper comes with a specific conda environment that will be installed and updated by snakemake.



## Wrappers
### How to make a new one
See the repo and the official [snakemake-wrappers](https://snakemake-wrappers.readthedocs.io/en/stable/index.html#contribute) for examples.

Each workflow contains:
     - `wrapper.py` - creates the output for that rule. Has access to params, input, outputs etc of the snakefile of the rule (and of all other rules).
    - `environment.yaml` - conda environment for the wrapper. Will be created automatically by snakemake and used for executing the rule. Snakemake will update the environment when the rule file changes.
    - `meta.yaml` (optional) - contains documentation like the expected inputs and outputs, required parameters etc.
    - tf models or other stuff required by the job


### Existing wrappers
#### Ethotracker
- description
- parameters:
	- processor
	- threshold

#### Deepposekit
- description
- parameters:
	- modelname





### Troubleshooting bugs in snakemake and conda
- For some envs, snakemake can't identify the python because (in the case of sleap) `python --version` does not return in the expected format. Just override this in `snakemake/script.py:
```python
 def _get_python_version(self):
        out = self._execute_cmd("python --version", read=True).strip()
        if not len(out):
             out = "Python 3.5"
        return tuple(map(int, PY_VER_RE.match(out).group("ver_min").split(".")))
```
- I had trouble testing this on windows, with the conda envs being created somewhere else - this is because of the way the env creation command is assembled by snakemake (in snakemake/deployment/conda.py:line304) - the path is quoted, which conda interprets as a relative path. Remove the quotes in  conda.py:line304 - should like like `"--file {}".format...` and `"--prefix {}".format...`.
